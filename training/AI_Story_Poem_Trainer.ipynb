{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Fine-Tune GPT-2 for Story & Poem Generation\n",
                "\n",
                "This notebook allows you to fine-tune a GPT-2 model on your own text data using a free GPU on Google Colab."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Install Dependencies"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install transformers datasets accelerate torch huggingface_hub"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Your Data\n",
                "\n",
                "You need a file named `train_data.txt`. \n",
                "1. Click the **Folder icon** on the left sidebar.\n",
                "2. Drag and drop your `train_data.txt` file there.\n",
                "\n",
                "If you don't have one, run the cell below to create a small dummy dataset for testing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "if not os.path.exists(\"train_data.txt\"):\n",
                "    print(\"Creating dummy train_data.txt...\")\n",
                "    with open(\"train_data.txt\", \"w\") as f:\n",
                "        f.write(\"Write a poem about Rain:\\nThe rain falls gently on the roof, a rhythmic tapping, a soothing proof.\\n\\n\")\n",
                "        f.write(\"Story about The Sun:\\nThe sun shone brightly over the valley. It was a day unlike any other, where the birds sang melodies of old.\\n\\n\")\n",
                "        f.write(\"Write a poem about Love:\\nLove is a rose, a tender bloom, dispelling shadows, chasing gloom.\\n\\n\")\n",
                "        # Add more examples here to test!\n",
                "    print(\"Created!\")\n",
                "else:\n",
                "    print(\"train_data.txt already exists.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Script"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
                "from transformers import Trainer, TrainingArguments\n",
                "\n",
                "def fine_tune_gpt2(\n",
                "    model_name=\"gpt2\",\n",
                "    output_dir=\"./finetuned_model\",\n",
                "    train_file=\"train_data.txt\",\n",
                "    epochs=3,\n",
                "    batch_size=4\n",
                "):\n",
                "    # 1. Load Tokenizer and Model\n",
                "    print(f\"Loading {model_name}...\")\n",
                "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
                "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
                "    tokenizer.pad_token = tokenizer.eos_token\n",
                "\n",
                "    # 2. Prepare Dataset\n",
                "    print(f\"Loading dataset from {train_file}...\")\n",
                "    train_dataset = TextDataset(\n",
                "        tokenizer=tokenizer,\n",
                "        file_path=train_file,\n",
                "        block_size=128,\n",
                "        overwrite_cache=True\n",
                "    )\n",
                "    \n",
                "    data_collator = DataCollatorForLanguageModeling(\n",
                "        tokenizer=tokenizer, mlm=False,\n",
                "    )\n",
                "\n",
                "    # 3. Training Arguments\n",
                "    training_args = TrainingArguments(\n",
                "        output_dir=output_dir,\n",
                "        overwrite_output_dir=True,\n",
                "        num_train_epochs=epochs,\n",
                "        per_device_train_batch_size=batch_size,\n",
                "        save_steps=500,\n",
                "        save_total_limit=2,\n",
                "        prediction_loss_only=True,\n",
                "        learning_rate=5e-5,\n",
                "    )\n",
                "\n",
                "    # 4. Initialize Trainer\n",
                "    trainer = Trainer(\n",
                "        model=model,\n",
                "        args=training_args,\n",
                "        data_collator=data_collator,\n",
                "        train_dataset=train_dataset,\n",
                "    )\n",
                "\n",
                "    # 5. Train\n",
                "    print(\"Starting training...\")\n",
                "    trainer.train()\n",
                "    \n",
                "    # 6. Save Model locally\n",
                "    print(f\"Saving model to {output_dir}...\")\n",
                "    model.save_pretrained(output_dir)\n",
                "    tokenizer.save_pretrained(output_dir)\n",
                "    print(\"Done!\")\n",
                "\n",
                "# Run the training\n",
                "fine_tune_gpt2(epochs=5, batch_size=8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Test the Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import pipeline\n",
                "\n",
                "generator = pipeline('text-generation', model='./finetuned_model')\n",
                "\n",
                "prompt = \"Write a poem about The Moon:\"\n",
                "output = generator(prompt, max_length=100, num_return_sequences=1)\n",
                "print(output[0]['generated_text'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Upload to Hugging Face (Optional)\n",
                "To use this model in your deployed backend, you need to push it to the Hugging Face Hub."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from huggingface_hub import notebook_login\n",
                "notebook_login()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
                "\n",
                "# Load the fine-tuned model\n",
                "model = GPT2LMHeadModel.from_pretrained(\"./finetuned_model\")\n",
                "tokenizer = GPT2Tokenizer.from_pretrained(\"./finetuned_model\")\n",
                "\n",
                "# Push to Hub\n",
                "# Replace 'your-username/your-model-name' with your actual details\n",
                "model_name_on_hub = \"your-username/my-story-poem-gpt2\"\n",
                "model.push_to_hub(model_name_on_hub)\n",
                "tokenizer.push_to_hub(model_name_on_hub)\n",
                "\n",
                "print(f\"Model pushed to https://huggingface.co/{model_name_on_hub}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}